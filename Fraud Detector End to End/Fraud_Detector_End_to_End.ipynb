{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to the Amazon Fraud Detector API  \n",
    "#### Supervised fraud detection  \n",
    "-------\n",
    "- [Introduction](#Introduction)\n",
    "- [Setup](#Setup)\n",
    "- [Plan](#Plan)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "-------\n",
    "\n",
    "Amazon Fraud Detector is a fully managed service that makes it easy to identify potentially fraudulent online activities such as online payment fraud and the creation of fake accounts. Fraud Detector capitalizes on the latest advances in machine learning (ML) and 20 years of fraud detection expertise from AWS and Amazon.com to automatically identify potentially fraudulent activity so you can catch more fraud faster. \n",
    "\n",
    "In this notebook, we'll use the Amazon Fraud Detector API to create a dector, train a model, and author rules. Next we'll apply the detector on sample data to identify potentially fraudlent envents. After running this notebook you should be able to: \n",
    "\n",
    "- Create a Detector  \n",
    "- Train a Machine Learning(ML) Model   \n",
    "- Author Rules to identify potiental fraud based on the model's score \n",
    "- Apply the Detector's \"predict\" function, to generate a model score and rule outcomes on data  \n",
    "\n",
    "If you would like to know more, please check out the [Fraud Detector's Documentation](https://docs.aws.amazon.com/frauddetector/). \n",
    "\n",
    "\n",
    "## Setup\n",
    "------\n",
    "First setup your AWS credentials so that Fraud Detector can store and access training data and supporting detector artifacts \n",
    "\n",
    "\n",
    "### Setting up AWS Credentials & Permissions\n",
    "\n",
    "https://docs.aws.amazon.com/frauddetector/latest/ug/set-up.html\n",
    "\n",
    "see: Sample Fraud Detector - Create IAM Role  \n",
    "\n",
    "To use Amazon Fraud Detector, you have to set up permissions that allow access to the Amazon Fraud Detector console and API operations. You also have to allow Amazon Fraud Detector to perform tasks on your \n",
    "behalf and to access resources that you own.\n",
    "\n",
    "We recommend creating an AWS Identify and Access Management (IAM) user with access restricted to Amazon Fraud Detector operations and required permissions. You can add other permissions as needed.\n",
    "\n",
    "The following policies provide the required permission to use Amazon Fraud Detector:\n",
    "\n",
    "- *AmazonFraudDetectorFullAccessPolicy*  \n",
    "    Allows you to perform the following actions:  \n",
    "        - Access all Amazon Fraud Detector resources  \n",
    "        - List and describe all model endpoints in Amazon SageMaker  \n",
    "        - List all IAM roles in the account  \n",
    "        - List all Amazon S3 buckets  \n",
    "        - Allow IAM Pass Role to pass a role to Amazon Fraud Detector  \n",
    "\n",
    "- *AmazonS3FullAccess*  \n",
    "    Allows full access to Amazon S3. This is required to upload training files to S3.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Plan\n",
    "### Plan a Fraud Detector\n",
    "------\n",
    "A *Detector* contains the model(s) and rule(s) detection logic for a particular type of fraud that you want to detect. We'll use the following 5 step process to plan a Fraud Detector: \n",
    "\n",
    "1. Define your Detector   \n",
    "    - What is the Name of the Detector \n",
    "    - How would you describe the Detector \n",
    "    \n",
    "2. Define & Train your Model   \n",
    "    - What do you want to call your Model \n",
    "    - What dataset are you going to train your Model with\n",
    "    - Promote your model \n",
    "    \n",
    "3. Author your Rules   \n",
    "    - What are your detection outcomes: Approve, Investigate, Refer \n",
    "    - For each rule you author:\n",
    "        - what logic do you want to apply to get an outcome - provided logic to generate approve, investigate, decline rules \n",
    "        \n",
    "4. Assemble the Detector  \n",
    "    - Which Model(s) & Version \n",
    "    - Which Rule(s) & Version \n",
    "    \n",
    "5. Test your Detector \n",
    "    - Interactively call predict on a single record \n",
    "    - Apply your Detector to a set of records  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "display(HTML(\"<style>.container { width:90% }</style>\"))\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# -- AWS stuff -- \n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# -- sklearn --\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, roc_auc_score\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize AWS Fraud Detector Client \n",
    "------\n",
    "\n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/frauddetector.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- fraud detector client\n",
    "client = boto3.client('frauddetector')\n",
    "# -- suffix is appended to detector and model name for uniqueness  \n",
    "sufx   = datetime.now().strftime(\"%Y%m%d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define your Detector  \n",
    "-----\n",
    "    - What do you want to Name the Detector? \n",
    "    - How would you describe the Detector?\n",
    "    \n",
    "    \n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Detector Name </strong>\n",
    "\n",
    "- Detector names can contain: lowercase a-z and contain 0-9 and underscores, for example <b> your_1st_detector</b> is valid  \n",
    "- If you plan on using the Prediction API notebook make note of your DETECTOR and MODEL NAME / Version\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- give your detector a name, it should be lowercase and contain a-z 0-9 and underscores -- \n",
    "DETECTOR_NAME = \"fraud_d_\" + sufx                          \n",
    "DETECTOR_DESC = \"detects synthetic fraud events created:\" + sufx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- put detector, initalizes your detector -- \n",
    "response = client.put_detector(detectorId  = DETECTOR_NAME, description = DETECTOR_DESC )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Define & Train your Model  \n",
    "------\n",
    "    - What do you want to Name your model?\n",
    "    - How would you describe your model?\n",
    "    - Do you have a iam role defined to acess the s3 bucket where your CSV file lives?\n",
    "    - Map the mandatory variables and enrichment variables \n",
    "    - Kick off training \n",
    "\n",
    "\n",
    "#### 2a. Bucket, Dataset, ARN, Model Name & Description  \n",
    "- You will need the following pieces of information to get started:\n",
    "    - S3 bucket name   \n",
    "    - S3 file URL   \n",
    "    - ARN/IAM role  see: https://docs.aws.amazon.com/frauddetector/latest/ug/set-up.html  \n",
    "    - Name & Describe your Model \n",
    "    \n",
    "#### 2b. Load & Profile your Data \n",
    "- Eyeball the file, does it look ok?\n",
    "  \n",
    "#### 2c. Define Variables & Roles   \n",
    "- Mandatory Varibles\n",
    "    - map: event_timestamp, ip_address, and email address \n",
    "- Enrichment Variables \n",
    "    - map: user_agent, card_bin, phone etc... fields that have specific enrichments \n",
    "   \n",
    "- Automatically add additional numeric / categorical fields to your model  \n",
    "    - preview the fields included in your model  \n",
    "    \n",
    "- Specify any fields to exclude from your model  \n",
    "    - specify any excluded fields  \n",
    "\n",
    "#### 2d. Train your model  \n",
    "\n",
    "#### 2e. Promote your model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### 2a. Bucket, Dataset, ARN, Model Name & Description \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Buckets, ARN and Model Name </strong>\n",
    "\n",
    "- S3_BUCKET is the name of the bucket where your file lives\n",
    "- S3_FILE is the URL to your s3 file\n",
    "- ARN_ROLE is the data access role \"ARN\" for the training data source. \n",
    "\n",
    "<b> Model Information:</b>  \n",
    "- MODEL_NAME - must be unique and can contain lowercase a-z, 0-9 and underscores, for example <b> your_1st_model</b> is valid  \n",
    "- MODEL_DESC - optional free text describing your model name.  \n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "```\n",
    "Note: To use Amazon Fraud Detector, you have to set up permissions that allow access to the Amazon Fraud\n",
    "Detector console and API operations. You also have to allow Amazon Fraud Detector to perform tasks on\n",
    "your behalf and to access resources that you own. We recommend creating an AWS Identify and Access Management (IAM) user with access restricted to. Amazon Fraud Detector operations and required permissions. You can add other permissions as needed. See \"Create an IAM User and Assign Required Permissions\" in the user's guide:\n",
    "```\n",
    "https://docs.aws.amazon.com/frauddetector/latest/ug/frauddetector.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_FILE    = \"s3://your-s3-bucket-name/your-csv-file.csv\" # -- s3 file url \n",
    "ARN_ROLE   = \"arn:aws:iam::XXXXX:role/service-role/AmazonFraudDetector-DataAccessRole-XXXX\" # -- The data access role ARN for the training data source. \n",
    "MODEL_NAME = \"your_fraud_model_\" +  sufx  # -- give your detector a name, it should be lowercase and contain a-z 0-9 and underscores \n",
    "MODEL_DESC = \"model trained on: \" + S3_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. Load & Profile your Data \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Eyeball the first 10 Records </strong>\n",
    "\n",
    "- does your data look reasonable? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(S3_FILE)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. Define Variables & Roles \n",
    "Fraud Detector models have 4 required fields: \n",
    "    - event_timestamp\n",
    "    - ip_address\n",
    "    - email_address\n",
    "    - fraud_label\n",
    "    \n",
    "Enrichment fields can include things like USERAGENT, PHONE, CARD_BIN etc. see documentation \n",
    "    - user_agent\n",
    "    - card_bin\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Map Requried and Enrichment Fields </strong>\n",
    "\n",
    "- Specify your FRAUD_LABEL field, this is the column name that you are atempting to predict \n",
    "- Map required(EVENT_TIMSTAMP, IP_ADDRESS, and EMAIL_ADDRESS) fields to column names, these are required  \n",
    "- Map optional enrichment fields \n",
    "- List any fields to exclude from your datasource \n",
    "\n",
    "Note: all other numeric fields will be mapped as custom numeric fields, and character fields will be mapped to custom character fields \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- map fraud label \n",
    "FRAUD_LABEL     = \"your-fraud-label-field\"\n",
    "\n",
    "# -- map required fields dictionary\n",
    "required_features = {\n",
    "    \"EVENT_TIMESTAMP\" : \"your-timestamp-field\",\n",
    "    \"IP_ADDRESS\"      : \"your-ip-address-field\",\n",
    "    \"EMAIL_ADDRESS\"   : \"your-email-address-field\",\n",
    "}\n",
    "# -- map optional enrichment fields dictionary\n",
    "enrichment_features = {\n",
    "}\n",
    "\n",
    "# -- list any fields you want to exlcude \n",
    "drop_fields = [ \"drop-field_1\" ]\n",
    "\n",
    "\n",
    "required_fields = list(required_features.values()) + list(enrichment_features.values())\n",
    "required_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics \n",
    "- This section provides a quick validation check on each field in the system\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Eyeball Summary Statisitcs </strong>\n",
    "\n",
    "- check identifies issues with nulls and nunique_pct % \n",
    "- returns a summary statisitcs and <b> excluded fields based on null and unique checks </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stats(df):\n",
    "    \"\"\" Generate summary statsitics for a panda's data frame \n",
    "        \n",
    "        Args:\n",
    "            df (DataFrame): panda's dataframe to create summary statisitcs for.\n",
    "        \n",
    "        Todo: \n",
    "            - add screening & integrity checks \n",
    "            - convert EVENT_TIMESTAMP to datetime \n",
    "            - add some data profiling \n",
    "    \n",
    "        Returns:\n",
    "            DataFrame of summary statistics \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    rowcnt = len(df)\n",
    "    df_s1  = df.agg(['count', 'nunique']).transpose().reset_index().rename(columns={\"index\":\"_column\"})\n",
    "    df_s1[\"null\"] = (rowcnt - df_s1[\"count\"]).astype('int64')\n",
    "    df_s1[\"not_null\"] = rowcnt - df_s1[\"null\"]\n",
    "    df_s1[\"null_pct\"] = df_s1[\"null\"] / rowcnt\n",
    "    df_s1[\"nunique_pct\"] = df_s1['nunique']/ rowcnt\n",
    "    dt = pd.DataFrame(df.dtypes).reset_index().rename(columns={\"index\":\"_column\", 0:\"_dtype\"})\n",
    "    df_stats = pd.merge(dt, df_s1, on='_column', how='inner').round(4)\n",
    "    df_stats['nunique'] = df_stats['nunique'].astype('int64')\n",
    "    df_stats['count'] = df_stats['count'].astype('int64')\n",
    "    \n",
    "    # -- null check \n",
    "    df_stats['null_check'] =  df_stats['null_pct'].apply(lambda x: 'Pass' if x <= 0.5 else '-- exclude --')\n",
    "    # -- unique check \n",
    "    df_stats['nunique_check'] =  df_stats['nunique_pct'].apply(lambda x: 'Pass' if x <= 0.9 else '-- exclude --')\n",
    "    # -- target check \n",
    "    \n",
    "    exclude_fields = df_stats.loc[(df_stats['null_check'] != 'Pass') | (df_stats['nunique_check'] != 'Pass') ]['_column'].to_list()\n",
    "    \n",
    "\n",
    "    print(\"--- summary stats ---\")\n",
    "    print(df_stats)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return df_stats, exclude_fields\n",
    "\n",
    "df_stats, exclude_fields = summary_stats(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> List additional Fields </strong>\n",
    "\n",
    "- Numeric and Character Fields that are NOT IN excluded fields list above, required fields, enrichment fields, drop_fields and fraud label will be automatically added as custom numeric and character fields \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- list of numeric features ---- \n",
    "numeric_features = [ c for c in df.select_dtypes(include=['float32', \"float64\", \"uint8\", 'int64']).columns if c not in required_fields + exclude_fields + drop_fields + [FRAUD_LABEL] ]\n",
    "print(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- list of categorical  features ---- \n",
    "categorical_features = [ c for c in df.select_dtypes(include=['object']).columns if c not in required_fields + exclude_fields + drop_fields + [FRAUD_LABEL]]\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong>Functions to Create Variables </strong>\n",
    "\n",
    "- The following functions will  **create all the variables** used by the model \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- no changes just run this code block ---\n",
    "def create_label(df, FRAUD_LABEL):\n",
    "    \"\"\"\n",
    "    Returns a dictionary for the model labelSchema, by identifying the rare event as fraud / and common as not-fraud \n",
    "    \n",
    "    Arguments:\n",
    "    df          -- input dataframe \n",
    "    FRAUD_LABEL -- the name of the field that contains fraud label  \n",
    "    \n",
    "    Returns:\n",
    "    labelSchema -- a dictionary containing labelKey & labelMapper \n",
    "    \"\"\"\n",
    "    label_summary = df[FRAUD_LABEL].value_counts()\n",
    "    labelSchema = {'labelKey': FRAUD_LABEL,\n",
    "                   \"labelMapper\" : { \"FRAUD\": [str(label_summary.idxmin())], \n",
    "                                     \"LEGIT\": [str(label_summary.idxmax())]}\n",
    "                  }\n",
    "    return labelSchema\n",
    "    \n",
    "# -- function to create all your variables --- \n",
    "def create_variables(required_features, enrichment_features, numeric_features, categorical_features, MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Returns a variable list of model input variables,it checks to see if variable exists,\n",
    "    if not then it addes the variable to Fraud Detector \n",
    "    \n",
    "    Arguments: \n",
    "    required_features    -- dictionary of required features (ip,email,timestamp)\n",
    "    enrichment_features  -- dictionary of optional features, mapped to specific variable types enriched (CARD_BIN, USERAGENT)\n",
    "    numeric_features     -- optional list of numeric field names \n",
    "    categorical_features -- optional list of categorical features \n",
    "    \n",
    "    Returns:\n",
    "    variable_list -- a list of variable dictionaries \n",
    "    \n",
    "    \"\"\"\n",
    "    variable_list = []\n",
    "    # -- first do the required fields \n",
    "    for feature in required_features.keys(): \n",
    "        variable_list.append( {'name' : required_features[feature]})\n",
    "        try:\n",
    "            client.get_variables(name=required_features[feature])\n",
    "        except:\n",
    "            print(\"Creating variable: \" + required_features[feature])\n",
    "            resp = client.create_variable(\n",
    "                    name = required_features[feature],\n",
    "                    dataType = 'STRING',\n",
    "                    dataSource ='EVENT',\n",
    "                    defaultValue = '<unknown>', \n",
    "                    description = required_features[feature],\n",
    "                    variableType = feature )\n",
    "    \n",
    "    for feature in enrichment_features.keys(): \n",
    "        variable_list.append( {'name' : enrichment_features[feature]})\n",
    "        try:\n",
    "            client.get_variables(name=enrichment_features[feature])\n",
    "        except:\n",
    "            print(\"Creating variable: \" + enrichment_features[feature])\n",
    "            resp = client.create_variable(\n",
    "                    name = enrichment_features[feature],\n",
    "                    dataType = 'STRING',\n",
    "                    dataSource ='EVENT',\n",
    "                    defaultValue = '<unknown>', \n",
    "                    description = enrichment_features[feature],\n",
    "                    variableType = feature )\n",
    "                \n",
    "               \n",
    "    # -- check and update the numeric features \n",
    "    for feature in numeric_features: \n",
    "        variable_list.append( {'name' : feature})\n",
    "        try:\n",
    "            client.get_variables(name=feature)\n",
    "        except:\n",
    "            print(\"Creating variable: \" + feature)\n",
    "            resp = client.create_variable(\n",
    "                    name = feature,\n",
    "                    dataType = 'FLOAT',\n",
    "                    dataSource ='EVENT',\n",
    "                    defaultValue = '0.0', \n",
    "                    description = feature,\n",
    "                    variableType = 'NUMERIC' )\n",
    "             \n",
    "    # -- check and update the categorical features \n",
    "    for feature in categorical_features: \n",
    "        variable_list.append( {'name' : feature})\n",
    "        try:\n",
    "            client.get_variables(name=feature)\n",
    "        except:\n",
    "            print(\"Creating variable: \" + feature)\n",
    "            resp = client.create_variable(\n",
    "                    name = feature,\n",
    "                    dataType = 'STRING',\n",
    "                    dataSource ='EVENT',\n",
    "                    defaultValue = '<unknown>', \n",
    "                    description = feature,\n",
    "                    variableType = 'CATEGORICAL' )\n",
    "    \n",
    "    # -- Model Score \n",
    "    model_feature = MODEL_NAME + \"_insightscore\"\n",
    "    # variable_list.append( {'name' : model_feature})\n",
    "    try:\n",
    "        client.get_variables(name=model_feature)\n",
    "    except:\n",
    "        print(\"Creating variable: \" + model_feature)\n",
    "        resp = client.create_variable(\n",
    "                name = model_feature,\n",
    "                dataType = 'FLOAT',\n",
    "                dataSource ='MODEL_SCORE',\n",
    "                defaultValue = '0.0', \n",
    "                description = model_feature,\n",
    "                variableType = 'NUMERIC' )\n",
    "    \n",
    "    return variable_list\n",
    "\n",
    "\n",
    "model_variables = create_variables(required_features, enrichment_features, numeric_features, categorical_features, MODEL_NAME)\n",
    "print(\"\\n --- model variable list/dict --\")\n",
    "print(model_variables)\n",
    "\n",
    "\n",
    "model_label = create_label(df,FRAUD_LABEL)\n",
    "print(\"\\n --- model label schema dict --\")\n",
    "print(model_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Train the Model \n",
    "-----\n",
    "Model training is a three part process \n",
    "1. intialize the model with PUT \n",
    "2. kick off training and wait \n",
    "3. once complete (assuming sucess) then promote to ACTIVE and wait \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Model Training </strong>\n",
    "\n",
    "- Model training takes about 50-60 minutes\n",
    "- Model promotion takes about 5-10 minutes \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- put initalizes the model, it's now ready to train \n",
    "response = client.put_model(\n",
    "    modelId     = MODEL_NAME,\n",
    "    modelType   = 'ONLINE_FRAUD_INSIGHTS',\n",
    "    description = MODEL_DESC,\n",
    "    trainingDataSource = {\n",
    "        'dataLocation'     : S3_FILE,\n",
    "        'dataAccessRoleArn': ARN_ROLE\n",
    "    },\n",
    "    modelVariables = model_variables ,\n",
    "    labelSchema    = model_label\n",
    ")\n",
    "print(\"\\n -- setup model --\")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- kick off model training   -- \n",
    "response = client.create_model_version (\n",
    "   modelId =  MODEL_NAME,\n",
    "   modelType = \"ONLINE_FRAUD_INSIGHTS\",\n",
    "   description = MODEL_DESC\n",
    ")\n",
    "print(\"\\n -- kick off model training  --\\n\")\n",
    "print(response)\n",
    "\n",
    "# -- model training can take a long time, we'll loop until it's complete  -- \n",
    "print(\"\\n -- wait till model completes training  --\")\n",
    "stime = time.time()\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = client.get_model_version(modelId=MODEL_NAME, modelType = \"ONLINE_FRAUD_INSIGHTS\", modelVersionNumber = '1.0')\n",
    "    if response['status'] == 'TRAINING_IN_PROGRESS':\n",
    "        print(f\"current progress: {(time.time() - stime)/60:{3}.{3}} minutes\")\n",
    "        time.sleep(60)  # -- sleep for 60 seconds \n",
    "    if response['status'] != 'TRAINING_IN_PROGRESS':\n",
    "        print(\"Model status : \" +  response['status'])\n",
    "        break\n",
    "        \n",
    "etime = time.time()\n",
    "\n",
    "# -- summarize \n",
    "print(\"\\n --- model training complete  --\")\n",
    "print(\"Elapsed time : %s\" % (etime - stime) + \" seconds \\n\"  )\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- once trained, change status to ACTIVE -- \n",
    "response = client.update_model_version( \n",
    " description = MODEL_DESC,\n",
    " modelId = MODEL_NAME,\n",
    " modelType = \"ONLINE_FRAUD_INSIGHTS\",\n",
    " modelVersionNumber = \"1.0\",\n",
    " status = \"ACTIVE\"   \n",
    ")\n",
    "\n",
    "\n",
    "#-- wait until model is active \n",
    "print(\"--- model status changing to active  \")\n",
    "stime = time.time()\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = client.get_model_version(modelId=MODEL_NAME, modelType = \"ONLINE_FRAUD_INSIGHTS\", modelVersionNumber = '1.0')\n",
    "    if response['status'] != 'ACTIVE':\n",
    "        print(f\"current progress: {(time.time() - stime)/60:{3}.{3}} minutes\")\n",
    "        time.sleep(60)  # sleep for 1 minute \n",
    "    if response['status'] == 'ACTIVE':\n",
    "        print(\"Model status : \" +  response['status'])\n",
    "        break\n",
    "        \n",
    "etime = time.time()\n",
    "print(\"Elapsed time : %s\" % (etime - stime) + \" seconds \\n\"  )\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model ROC Plot \n",
    "------\n",
    "this produces a ROC chart with AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- model performance summary -- \n",
    "auc = fpr = eval(client.describe_model_versions(\n",
    "    modelId= MODEL_NAME,\n",
    "    modelVersionNumber='1.0',\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    maxResults=10\n",
    ")['modelVersionDetails'][0]['trainingMetrics']['auc'])\n",
    "\n",
    "thr = eval(client.describe_model_versions(\n",
    "    modelId= MODEL_NAME,\n",
    "    modelVersionNumber='1.0',\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    maxResults=10\n",
    ")['modelVersionDetails'][0]['trainingMetrics']['thresholds'])\n",
    "\n",
    "\n",
    "fpr = eval(client.describe_model_versions(\n",
    "    modelId= MODEL_NAME,\n",
    "    modelVersionNumber='1.0',\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    maxResults=10\n",
    ")['modelVersionDetails'][0]['trainingMetrics']['fpr'])\n",
    "\n",
    "tpr = eval(client.describe_model_versions(\n",
    "    modelId= MODEL_NAME,\n",
    "    modelVersionNumber='1.0',\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    maxResults=10\n",
    ")['modelVersionDetails'][0]['trainingMetrics']['tpr'])\n",
    "\n",
    "precision = eval(client.describe_model_versions(\n",
    "    modelId= MODEL_NAME,\n",
    "    modelVersionNumber='1.0',\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    maxResults=10\n",
    ")['modelVersionDetails'][0]['trainingMetrics']['precision'])\n",
    "precision\n",
    "\n",
    "df_model = pd.DataFrame(list(zip(thr, fpr, tpr, precision)), columns=['thr','fpr', 'tpr', 'precision'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.3f)' % auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title( MODEL_NAME + ' ROC Chart')\n",
    "plt.legend(loc=\"lower right\",fontsize=12)\n",
    "plt.axvline(x = 0.02 ,linewidth=2, color='r')\n",
    "plt.axhline(y = 0.73 ,linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble the Detector  \n",
    "\n",
    "\n",
    "-----\n",
    "Creating a detector is a 5 part process: \n",
    "\n",
    "1. setup outcomes & rules \n",
    "2. create outcomes \n",
    "3. create rules \n",
    "4. create detector \n",
    "5. promote detector \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Authoring Rules </strong>\n",
    "\n",
    "- Eyeball the sample rules for say 1%, 2%, 3% or 4% FPR \n",
    "\n",
    "- if in doubt note the threshold coresponding to 1% and use that in the next step\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stat = df_model.round(decimals=2)               \n",
    "m = model_stat.loc[model_stat.groupby([\"fpr\"])[\"thr\"].idxmax()] \n",
    "\n",
    "def make_rule(x):\n",
    "    return \"\\'$\" + MODEL_NAME + \"_insightscore > \" + str(x) + \"\\'\"\n",
    "    \n",
    "m['rule'] = m['thr'].apply(lambda x: make_rule(x))\n",
    "\n",
    "print (\" --- score thresholds 1% to 10% --- \")\n",
    "print(m[[\"fpr\", \"tpr\", \"thr\", \"rule\"]].loc[(m['fpr'] > 0.0 ) & (m['fpr'] <= 0.1)].reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Outcomes and Rules \n",
    "-----\n",
    "the following dictionary contains both outcomes and sample rules \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Addiging & Editing Rules </strong>\n",
    "\n",
    "- See the sample rules above, feel free to add an outcome and additional rules... in this case an outcome is mapped 1 to 1 with a rule but you can have an outcome map to as many rules as you'd like. \n",
    "\n",
    "<i>**Note: the _insightscores below are just place holders, you can add outcomes and \"threshold\" based rules as you like. just fit them into the OUTCOMES_AND_RULES dictionary.**</i>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Here i create a rule for each outcome, the outcome's description is the rule expression\n",
    "OUTCOMES_AND_RULES = {\n",
    "  \"approve\"     : f\"${MODEL_NAME}_insightscore < 100\",\n",
    "  \"investigate\" : f\"${MODEL_NAME}_insightscore >= 100 and ${MODEL_NAME}_insightscore < 200\",\n",
    "  \"decline\"     : f\"${MODEL_NAME}_insightscore >= 200 and ${MODEL_NAME}_insightscore < 600\",\n",
    "  \"alert\"       : f\"${MODEL_NAME}_insightscore >= 600\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outcomes(client, OUTCOMES_AND_RULES):\n",
    "    \"\"\" create Fraud Detector Outcomes \n",
    "    \n",
    "    \"\"\"   \n",
    "    for key, value in OUTCOMES_AND_RULES.items():\n",
    "        print(\"creating outcome variable: \" + key)\n",
    "        response = client.put_outcome(\n",
    "                          name=key,\n",
    "                          description=value)\n",
    "    \n",
    "create_outcomes(client, OUTCOMES_AND_RULES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong>Create Rules </strong>\n",
    "\n",
    "- This function creates a sample rule FOR EACH outcome in the OUTCOMES_AND_RULES dictionary above. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_rules(client, OUTCOMES_AND_RULES):\n",
    "    \"\"\" create rules for each outcome based on the outcome description \n",
    "    \n",
    "    \"\"\"\n",
    "    rule_list = []\n",
    "    \n",
    "    for key in OUTCOMES_AND_RULES.keys():\n",
    "        ruleId = key + \"_\" + MODEL_NAME + \"_rule\"\n",
    "        detectorId = DETECTOR_NAME\n",
    "        try:\n",
    "            response = client.get_rules(\n",
    "                    ruleId      = ruleId,\n",
    "                    detectorId  = DETECTOR_NAME )\n",
    "            vers = response['ruleDetails'][0]['ruleVersion']\n",
    "            rule = {\"ruleId\" :ruleId,\n",
    "                    \"ruleVersion\" : vers,\n",
    "                    \"detectorId\" : detectorId}\n",
    "            rule_list.append(rule)\n",
    "            # print(\"Updating existing rule: \"+ ruleId )\n",
    "            \n",
    "        except:\n",
    "            # print(\"Creating rule: \" +  ruleId )\n",
    "            response = client.create_rule(\n",
    "                    ruleId      = ruleId,\n",
    "                    detectorId  = DETECTOR_NAME,\n",
    "                    description = OUTCOMES_AND_RULES[key],\n",
    "                    expression  = OUTCOMES_AND_RULES[key],\n",
    "                    language    ='DETECTORPL',\n",
    "                    outcomes    =[key])\n",
    "            vers = '1.0'\n",
    "            rule = {\"ruleId\" :ruleId,\n",
    "                    \"ruleVersion\" : vers,\n",
    "                    \"detectorId\" : detectorId}\n",
    "            \n",
    "            rule_list.append(rule)\n",
    "    return rule_list \n",
    "            \n",
    "\n",
    "rule_list = create_rules(client, OUTCOMES_AND_RULES)\n",
    "print(\"\\n -- rule list --\")\n",
    "print(rule_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Detector \n",
    "----\n",
    "Finally, we can create the detector. It is a two part process \n",
    "1. create the detector Version\n",
    "2. activate the detection (change the status to ACTIVE)\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Detectors </strong>\n",
    "\n",
    "- PUT - creates an empty detector \n",
    "- CREATE Version - assembles the detector, model(s) and rules(s), \n",
    "- UPDATE - changes the status from DRAFT to ACTIVE \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.create_detector_version(\n",
    "    detectorId  = DETECTOR_NAME,\n",
    "    description = DETECTOR_DESC,\n",
    "    modelVersions = [{\"modelId\":MODEL_NAME, \n",
    "                     \"modelType\" : \"ONLINE_FRAUD_INSIGHTS\",\n",
    "                     \"modelVersionNumber\" : \"1.0\"}],\n",
    "    rules = rule_list\n",
    ")\n",
    "print(\"\\n -- detector created -- \")\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.update_detector_version_status(\n",
    "    detectorId= DETECTOR_NAME,\n",
    "    detectorVersionId='1.0',\n",
    "    status='ACTIVE'\n",
    ")\n",
    "print(\"\\n -- detector activated -- \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Your Detector \n",
    "-----\n",
    "\n",
    "- pass a single record to your Detector\n",
    "- pass a set of records to your Detector \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Infrencing, Scoring & Decision-ing </strong>\n",
    "\n",
    "Now you have a detector that is comprised of a model that produces a score and rules that produce outcomes.  \n",
    "\n",
    "In realtime AWS' Fraud Detector will perform the following durring infrence:\n",
    "- deal with missing values \n",
    "- enrich your data \n",
    "- transform you data \n",
    "- apply 0 - N models \n",
    "- apply 1 - N rules \n",
    "- return a result \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_variables(MODEL_NAME):\n",
    "    \"\"\" return list of variables used by a model \n",
    "    \n",
    "    \"\"\"\n",
    "    response = client.get_models(\n",
    "    modelType='ONLINE_FRAUD_INSIGHTS',\n",
    "    modelId= MODEL_NAME)\n",
    "    model_variables = []\n",
    "\n",
    "    for v in response['models'][0]['modelVariables']:\n",
    "        model_variables.append(v['name'])\n",
    "    return model_variables\n",
    "\n",
    "model_variables = get_model_variables(MODEL_NAME)\n",
    "print(\"\\n -- model variables -- \")\n",
    "print(model_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- predict on a single record  \n",
    "pred_data = df[model_variables].head(1).astype(str).to_dict(orient='records')\n",
    "\n",
    "for rec in pred_data:\n",
    "    stime = time.time()\n",
    "    pred = client.get_prediction(detectorId=DETECTOR_NAME, detectorVersionId='1.0', eventId='1', eventAttributes=rec)         \n",
    "    etime = time.time()\n",
    "    print(str(pred['modelScores'][0]['scores'][MODEL_NAME + '_insightscore']) + \" - score in = %s\" % round((etime - stime)*1000,2) + \" ms\")\n",
    "    print(\"\\n\",pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on a Set of Records \n",
    "\n",
    "<div class=\"alert alert-info\"> ðŸ’¡ <strong> Evaluate </strong>\n",
    "\n",
    "-  Change **record_count** to the number of rectods you want to predict  \n",
    "\n",
    "</div>\n",
    "\n",
    "#### Alternatively, if you want to predict on a different dataset\n",
    "\n",
    "- Simply create a new data frame to score on. \n",
    "\n",
    "```python\n",
    "\n",
    "# -- in this case the prediction dataframe is called \"df\" \n",
    "\n",
    "df = pd.read_csv(new-dataset-to-predict-on.csv)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- to predict on a subset of records simply change record count \n",
    "record_count = 1000\n",
    "\n",
    "pred_data = df[model_variables].head(record_count).astype(str).to_dict(orient='records')\n",
    "dat = []\n",
    "i=0\n",
    "for rec in pred_data:\n",
    "    # print(rec)\n",
    "    clear_output(wait=True)\n",
    "    stime = time.time()\n",
    "    pred = client.get_prediction(detectorId=DETECTOR_NAME, detectorVersionId='1.0', eventId=str(i), eventAttributes=rec)         \n",
    "    etime = time.time()\n",
    "    rec['score'] = pred['modelScores'][0]['scores'][MODEL_NAME + '_insightscore']\n",
    "    rec['score_ms'] = ((etime - stime)*1000)\n",
    "    rec['rule_outcome'] = ['outcomes'][0]\n",
    "    dat.append(rec)\n",
    "    i += 1 \n",
    "    print(\"current progress: \", round((i/record_count)*100,2), \"%\" )\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eyeball a sample of predictions \n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Review sample of predictions \n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionally Write Predictions to File\n",
    "\n",
    "<div class=\"alert alert-info\"> <strong> Write Predictions </strong>\n",
    "\n",
    "- You can write your prediction dataset to a CSV to manually review predictions\n",
    "- Simply add a cell below and copy the code below\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# -- optionally write predictions to a CSV file -- \n",
    "predictions.to_csv(MODEL_NAME + \".csv\", index=False)\n",
    "# -- or to a XLS file \n",
    "predictions.to_excel(MODEL_NAME + \".xlsx\", index=False)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
